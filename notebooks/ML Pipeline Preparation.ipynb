{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/will/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/will/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import nltk\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "4  12  says: west side of Haiti, rest of the country ...   \n",
       "\n",
       "                                            original   genre related request  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct       1       0   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct       1       0   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct       1       0   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct       1       1   \n",
       "4  facade ouest d Haiti et le reste du pays aujou...  direct       1       0   \n",
       "\n",
       "  offer aid_related medical_help medical_products      ...      aid_centers  \\\n",
       "0     0           0            0                0      ...                0   \n",
       "1     0           1            0                0      ...                0   \n",
       "2     0           0            0                0      ...                0   \n",
       "3     0           1            0                1      ...                0   \n",
       "4     0           0            0                0      ...                0   \n",
       "\n",
       "  other_infrastructure weather_related floods storm fire earthquake cold  \\\n",
       "0                    0               0      0     0    0          0    0   \n",
       "1                    0               1      0     1    0          0    0   \n",
       "2                    0               0      0     0    0          0    0   \n",
       "3                    0               0      0     0    0          0    0   \n",
       "4                    0               0      0     0    0          0    0   \n",
       "\n",
       "  other_weather direct_report  \n",
       "0             0             0  \n",
       "1             0             0  \n",
       "2             0             0  \n",
       "3             0             0  \n",
       "4             0             0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///disaster_response.db')\n",
    "df = pd.read_sql(\"SELECT * FROM disaster_response\",engine) \n",
    "X = df.filter(items=['id', 'message', 'original', 'genre'])\n",
    "# here we drop child allone because we dont have a single message that is classified as such\n",
    "y = df.drop(['id', 'message', 'original', 'genre', 'child_alone'],  axis=1).astype(float)\n",
    "# transform all it on binary classification\n",
    "y['related']=y['related'].map(lambda x: 1 if x == 2 else x)\n",
    "\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(x).lower().strip() for x in tokens]\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "- You'll find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', RandomForestClassifier()) \n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "pipeline.fit(X_train['message'],y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the accuracy, precision and recall on both the training set and the test set. You can use sklearn's `classification_report` function here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = pipeline.predict(X_test['message'])\n",
    "y_pred_train = pipeline.predict(X_train['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.83      0.90      0.86      4962\n",
      "               request       0.83      0.35      0.49      1097\n",
      "                 offer       0.00      0.00      0.00        30\n",
      "           aid_related       0.75      0.40      0.52      2652\n",
      "          medical_help       0.44      0.01      0.02       508\n",
      "      medical_products       0.88      0.05      0.09       307\n",
      "     search_and_rescue       0.50      0.02      0.03       182\n",
      "              security       0.00      0.00      0.00       119\n",
      "              military       0.67      0.02      0.03       237\n",
      "                 water       0.84      0.12      0.21       398\n",
      "                  food       0.85      0.20      0.33       699\n",
      "               shelter       0.93      0.06      0.12       572\n",
      "              clothing       0.80      0.04      0.08        99\n",
      "                 money       0.80      0.03      0.05       147\n",
      "        missing_people       0.00      0.00      0.00        73\n",
      "              refugees       0.25      0.00      0.01       206\n",
      "                 death       0.92      0.03      0.07       316\n",
      "             other_aid       0.46      0.02      0.04       883\n",
      "infrastructure_related       0.00      0.00      0.00       405\n",
      "             transport       0.57      0.01      0.03       279\n",
      "             buildings       0.67      0.02      0.04       347\n",
      "           electricity       1.00      0.01      0.02       129\n",
      "                 tools       0.00      0.00      0.00        41\n",
      "             hospitals       0.00      0.00      0.00        68\n",
      "                 shops       0.00      0.00      0.00        22\n",
      "           aid_centers       0.00      0.00      0.00        72\n",
      "  other_infrastructure       0.00      0.00      0.00       273\n",
      "       weather_related       0.83      0.40      0.54      1777\n",
      "                floods       0.88      0.12      0.21       505\n",
      "                 storm       0.79      0.19      0.31       598\n",
      "                  fire       0.00      0.00      0.00        72\n",
      "            earthquake       0.89      0.31      0.46       591\n",
      "                  cold       0.67      0.02      0.03       126\n",
      "         other_weather       0.83      0.01      0.03       346\n",
      "         direct_report       0.80      0.29      0.42      1240\n",
      "\n",
      "           avg / total       0.73      0.38      0.43     20378\n",
      "\n",
      "********************************************************************************\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.99      1.00      1.00     15132\n",
      "               request       1.00      0.94      0.97      3377\n",
      "                 offer       1.00      0.76      0.86        88\n",
      "           aid_related       1.00      0.96      0.98      8208\n",
      "          medical_help       1.00      0.83      0.91      1576\n",
      "      medical_products       1.00      0.84      0.91      1006\n",
      "     search_and_rescue       1.00      0.77      0.87       542\n",
      "              security       1.00      0.73      0.85       352\n",
      "              military       1.00      0.78      0.88       623\n",
      "                 water       1.00      0.88      0.93      1274\n",
      "                  food       1.00      0.91      0.95      2224\n",
      "               shelter       1.00      0.89      0.94      1742\n",
      "              clothing       1.00      0.82      0.90       306\n",
      "                 money       1.00      0.79      0.88       457\n",
      "        missing_people       1.00      0.76      0.86       225\n",
      "              refugees       1.00      0.79      0.88       669\n",
      "                 death       1.00      0.84      0.91       878\n",
      "             other_aid       1.00      0.85      0.92      2563\n",
      "infrastructure_related       1.00      0.80      0.89      1300\n",
      "             transport       1.00      0.79      0.88       922\n",
      "             buildings       1.00      0.83      0.90       986\n",
      "           electricity       1.00      0.74      0.85       403\n",
      "                 tools       1.00      0.73      0.84       118\n",
      "             hospitals       1.00      0.77      0.87       215\n",
      "                 shops       1.00      0.72      0.84        98\n",
      "           aid_centers       1.00      0.78      0.88       237\n",
      "  other_infrastructure       1.00      0.78      0.87       878\n",
      "       weather_related       1.00      0.95      0.97      5520\n",
      "                floods       1.00      0.88      0.93      1650\n",
      "                 storm       1.00      0.92      0.96      1845\n",
      "                  fire       1.00      0.78      0.87       210\n",
      "            earthquake       1.00      0.92      0.96      1864\n",
      "                  cold       1.00      0.85      0.92       404\n",
      "         other_weather       1.00      0.79      0.88      1030\n",
      "         direct_report       1.00      0.92      0.96      3835\n",
      "\n",
      "           avg / total       1.00      0.92      0.95     62757\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.local/share/virtualenvs/scene-variations-ZwQ6vwJV/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test.values, y_pred_test, target_names=y.columns.values))\n",
    "print(\"********************************************************************************\")\n",
    "print(classification_report(y_train.values, y_pred_train, target_names=y.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5832 candidates, totalling 17496 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 30.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed: 48.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed: 70.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2426 tasks      | elapsed: 96.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3176 tasks      | elapsed: 126.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4026 tasks      | elapsed: 159.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4976 tasks      | elapsed: 196.7min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "parameters = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (None, 5000, 10000),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__max_depth': [10, 20, 30],\n",
    "    'clf__max_features': ['auto', 'sqrt'],\n",
    "    'clf__min_samples_leaf': [1, 2, 4],\n",
    "    'clf__min_samples_split': [2, 5, 10],\n",
    "    'clf__n_estimators': [10, 20, 40]}\n",
    "\n",
    "\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, scoring='f1_micro',verbose= 1,n_jobs =-1)\n",
    "cv.fit(X_train['message'], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = cv.predict(X_test['message'])\n",
    "y_pred_train = cv.predict(X_train['message'])\n",
    "print(classification_report(y_test.values, y_pred_test, target_names=y.columns.values))\n",
    "print(\"********************************************************************************\")\n",
    "print(classification_report(y_train.values, y_pred_train, target_names=y.columns.values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
